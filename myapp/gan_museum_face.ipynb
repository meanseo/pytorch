{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting utils\n",
            "  Downloading utils-1.0.1-py2.py3-none-any.whl (21 kB)\n",
            "Installing collected packages: utils\n",
            "Successfully installed utils-1.0.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "!pip3 install utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fFk1e7RWoR8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from utils.loaders import load_mnist\n",
        "from models.AE import Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJLJEcXjK697"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eacFBHOQ0hjx"
      },
      "source": [
        "# 새 섹션"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANUEUGS2XG5k"
      },
      "outputs": [],
      "source": [
        "# 실행 매개변수\n",
        "SECTION = 'vae'\n",
        "RUN_ID = '0001'\n",
        "DATA_NAME = 'digits'\n",
        "RUN_FOLDER = 'run/{}/'.format(SECTION)\n",
        "RUN_FOLDER += '_'.join([RUN_ID, DATA_NAME])\n",
        "\n",
        "if not os.path.exists(RUN_FOLDER):\n",
        "    os.mkdir(RUN_FOLDER)\n",
        "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
        "    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\n",
        "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
        "\n",
        "MODE =  'build' #'load' #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZsXC3V8duZ2"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = load_mnist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nU-VDFH1dyT4"
      },
      "outputs": [],
      "source": [
        "AE = Autoencoder(\n",
        "    input_dim = (28,28,1)\n",
        "    , encoder_conv_filters = [32,64,64, 64]\n",
        "    , encoder_conv_kernel_size = [3,3,3,3]\n",
        "    , encoder_conv_strides = [1,2,2,1]\n",
        "    , decoder_conv_t_filters = [64,64,32,1]\n",
        "    , decoder_conv_t_kernel_size = [3,3,3,3]\n",
        "    , decoder_conv_t_strides = [1,2,2,1]\n",
        "    , z_dim = 2\n",
        ")\n",
        "\n",
        "if MODE == 'build':\n",
        "    AE.save(RUN_FOLDER)\n",
        "else:\n",
        "    AE.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oWwuaHPeEp9"
      },
      "outputs": [],
      "source": [
        "AE.encoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6x80AoUpNfoK"
      },
      "outputs": [],
      "source": [
        "AE.decoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNfia7vFeIbH"
      },
      "outputs": [],
      "source": [
        "LEARNING_RATE = 0.0005\n",
        "BATCH_SIZE = 32\n",
        "INITIAL_EPOCH = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hQIPp_TeLnE"
      },
      "outputs": [],
      "source": [
        "AE.compile(LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8yp27lcwNHI"
      },
      "outputs": [],
      "source": [
        "\n",
        "AE.train(     \n",
        "    x_train[:1000]\n",
        "    , batch_size = BATCH_SIZE\n",
        "    , epochs = 200\n",
        "    , run_folder = RUN_FOLDER\n",
        "    , initial_epoch = INITIAL_EPOCH\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ACWKNt-wWny"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from scipy.stats import norm\n",
        "\n",
        "\n",
        "from models.AE import Autoencoder\n",
        "from utils.loaders import load_mnist, load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FE-B3wyiwvhW"
      },
      "outputs": [],
      "source": [
        "SECTION = 'vae'\n",
        "RUN_ID = '0001'\n",
        "DATA_NAME = 'digits'\n",
        "RUN_FOLDER = 'run/{}/'.format(SECTION)\n",
        "RUN_FOLDER += '_'.join([RUN_ID, DATA_NAME])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdNaXln5EVt5"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = load_mnist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mOKfKZDEfxY"
      },
      "outputs": [],
      "source": [
        "AE = load_model(Autoencoder, RUN_FOLDER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60d_TvI2Eifz"
      },
      "outputs": [],
      "source": [
        "n_to_show = 10\n",
        "np.random.seed(88)\n",
        "example_idx = np.random.choice(range(len(x_test)), n_to_show)\n",
        "example_images = x_test[example_idx]\n",
        "\n",
        "\n",
        "z_points = AE.encoder.predict(example_images)\n",
        "\n",
        "\n",
        "reconst_images = AE.decoder.predict(z_points)\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(15, 3))\n",
        "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "\n",
        "\n",
        "for i in range(n_to_show):\n",
        "    img = example_images[i].squeeze()\n",
        "    ax = fig.add_subplot(2, n_to_show, i+1)\n",
        "    ax.axis('off')\n",
        "    ax.text(0.5, -0.35, str(np.round(z_points[i],1)), fontsize=10, ha='center', transform=ax.transAxes)\n",
        "    ax.imshow(img, cmap='gray_r')\n",
        "\n",
        "\n",
        "for i in range(n_to_show):\n",
        "    img = reconst_images[i].squeeze()\n",
        "    ax = fig.add_subplot(2, n_to_show, i+n_to_show+1)\n",
        "    ax.axis('off')\n",
        "    ax.imshow(img, cmap='gray_r')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-_DqNOMVz9P"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download('run/vae/0001_digits/params.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRP3CeglWpnN"
      },
      "outputs": [],
      "source": [
        "files.download('run/vae/0001_digits/weights/weights.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hd64D9LpEnE3"
      },
      "outputs": [],
      "source": [
        "n_to_show = 5000\n",
        "grid_size = 15\n",
        "figsize = 10\n",
        "\n",
        "\n",
        "example_idx = np.random.choice(range(len(x_test)), n_to_show)\n",
        "example_images = x_test[example_idx]\n",
        "example_labels = y_test[example_idx]\n",
        "\n",
        "\n",
        "z_points = AE.encoder.predict(example_images)\n",
        "\n",
        "\n",
        "min_x = min(z_points[:, 0])\n",
        "max_x = max(z_points[:, 0])\n",
        "min_y = min(z_points[:, 1])\n",
        "max_y = max(z_points[:, 1])\n",
        "\n",
        "\n",
        "plt.figure(figsize=(figsize, figsize))\n",
        "plt.scatter(z_points[:, 0] , z_points[:, 1], c='black', alpha=0.5, s=2)\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auSduP0iEvsM"
      },
      "outputs": [],
      "source": [
        "figsize = 10\n",
        "\n",
        "\n",
        "plt.figure(figsize=(figsize, figsize))\n",
        "plt.scatter(z_points[:, 0] , z_points[:, 1], c='black', alpha=0.5, s=2)\n",
        "\n",
        "\n",
        "grid_size = 10\n",
        "grid_depth = 3\n",
        "figsize = 15\n",
        "\n",
        "\n",
        "x = np.random.uniform(min_x, max_x, size = grid_size * grid_depth)\n",
        "y = np.random.uniform(min_y, max_y, size = grid_size * grid_depth)\n",
        "z_grid = np.array(list(zip(x, y)))\n",
        "reconst = AE.decoder.predict(z_grid)\n",
        "\n",
        "\n",
        "plt.scatter(z_grid[:, 0] , z_grid[:, 1], c='red', alpha=1, s=20)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(figsize, grid_depth))\n",
        "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "\n",
        "\n",
        "for i in range(grid_size*grid_depth):\n",
        "    ax = fig.add_subplot(grid_depth, grid_size, i+1)\n",
        "    ax.axis('off')\n",
        "    ax.text(0.5, -0.35, str(np.round(z_grid[i],1)), fontsize=10, ha='center', transform=ax.transAxes)\n",
        "    \n",
        "    ax.imshow(reconst[i, :,:,0], cmap = 'Greys')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7NwQPYGEydh"
      },
      "outputs": [],
      "source": [
        "figsize = 10\n",
        "\n",
        "\n",
        "plt.figure(figsize=(figsize, figsize))\n",
        "plt.scatter(z_points[:, 0] , z_points[:, 1], cmap='rainbow', c=example_labels, alpha=0.5, s=2)\n",
        "plt.colorbar()\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvpXLeFVE0i3"
      },
      "outputs": [],
      "source": [
        "figsize = 10\n",
        "\n",
        "\n",
        "plt.figure(figsize=(figsize, figsize))\n",
        "plt.scatter(z_points[:, 0] , z_points[:, 1], cmap='rainbow', c=example_labels, alpha=0.5, s=2)\n",
        "plt.colorbar()\n",
        "\n",
        "\n",
        "bad_examples = np.array([[0, -1.5], [-8, -4.5], [6, -8]])\n",
        "plt.scatter(bad_examples[:, 0] , bad_examples[:, 1], c='black', alpha=1, s=20)\n",
        "\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "reconst = AE.decoder.predict(bad_examples)\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(figsize, grid_depth))\n",
        "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "\n",
        "\n",
        "for i in range(3):\n",
        "    ax = fig.add_subplot(grid_depth, grid_size, i+1)\n",
        "    ax.axis('off')\n",
        "    \n",
        "    ax.imshow(reconst[i, :,:,0], cmap = 'Greys')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRpdgk8fE4wz"
      },
      "outputs": [],
      "source": [
        "grid_size = 20\n",
        "\n",
        "\n",
        "example_idx = np.random.choice(range(len(x_test)), n_to_show)\n",
        "example_images = x_test[example_idx]\n",
        "example_labels = y_test[example_idx]\n",
        "\n",
        "\n",
        "z_points = AE.encoder.predict(example_images)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(figsize, figsize))\n",
        "plt.scatter(z_points[:, 0] , z_points[:, 1] , cmap='rainbow' , c=example_labels\n",
        "            , alpha=0.5, s=2)\n",
        "plt.colorbar()\n",
        "\n",
        "\n",
        "# x = norm.ppf(np.linspace(0.05, 0.95, 10))\n",
        "# y = norm.ppf(np.linspace(0.05, 0.95, 10))\n",
        "x = np.linspace(min(z_points[:, 0]), max(z_points[:, 0]), grid_size)\n",
        "y = np.linspace(max(z_points[:, 1]), min(z_points[:, 1]), grid_size)\n",
        "xv, yv = np.meshgrid(x, y)\n",
        "xv = xv.flatten()\n",
        "yv = yv.flatten()\n",
        "z_grid = np.array(list(zip(xv, yv)))\n",
        "\n",
        "\n",
        "reconst = AE.decoder.predict(z_grid)\n",
        "\n",
        "\n",
        "plt.scatter(z_grid[:, 0] , z_grid[:, 1], c = 'black'#, cmap='rainbow' , c= example_labels\n",
        "            , alpha=1, s=5)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(figsize, figsize))\n",
        "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "for i in range(grid_size**2):\n",
        "    ax = fig.add_subplot(grid_size, grid_size, i+1)\n",
        "    ax.axis('off')\n",
        "    ax.imshow(reconst[i, :,:,0], cmap = 'Greys')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2ulItjbGqpg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "\n",
        "from models.VAE import VariationalAutoencoder\n",
        "from utils.loaders import load_mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iy72XUE2GujN"
      },
      "outputs": [],
      "source": [
        "# 실행 매개변수\n",
        "SECTION = 'vae'\n",
        "RUN_ID = '0002'\n",
        "DATA_NAME = 'digits'\n",
        "RUN_FOLDER = 'run/{}/'.format(SECTION)\n",
        "RUN_FOLDER += '_'.join([RUN_ID, DATA_NAME])\n",
        "\n",
        "\n",
        "if not os.path.exists(RUN_FOLDER):\n",
        "    os.mkdir(RUN_FOLDER)\n",
        "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
        "    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\n",
        "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
        "\n",
        "\n",
        "mode =  'build' #'load' #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qki8G59MGweO"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = load_mnist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P35y5NfLGyo2"
      },
      "outputs": [],
      "source": [
        "vae = VariationalAutoencoder(\n",
        "    input_dim = (28,28,1)\n",
        "    , encoder_conv_filters = [32,64,64, 64]\n",
        "    , encoder_conv_kernel_size = [3,3,3,3]\n",
        "    , encoder_conv_strides = [1,2,2,1]\n",
        "    , decoder_conv_t_filters = [64,64,32,1]\n",
        "    , decoder_conv_t_kernel_size = [3,3,3,3]\n",
        "    , decoder_conv_t_strides = [1,2,2,1]\n",
        "    , z_dim = 2\n",
        ")\n",
        "\n",
        "\n",
        "if mode == 'build':\n",
        "    vae.save(RUN_FOLDER)\n",
        "else:\n",
        "    vae.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXnLgdEgG0bw"
      },
      "outputs": [],
      "source": [
        "vae.encoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dsPVAa5G9uc"
      },
      "outputs": [],
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(vae.encoder, to_file='vae_encoder.png', show_shapes = True, show_layer_names = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gXvliRiHuHv"
      },
      "outputs": [],
      "source": [
        "vae.decoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fb9q9tLH0AO"
      },
      "outputs": [],
      "source": [
        "LEARNING_RATE = 0.0005\n",
        "R_LOSS_FACTOR = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bb53HMIWH3rg"
      },
      "outputs": [],
      "source": [
        "vae.compile(LEARNING_RATE, R_LOSS_FACTOR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4y93SdlRH5P-"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "EPOCHS = 200\n",
        "PRINT_EVERY_N_BATCHES = 100\n",
        "INITIAL_EPOCH = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xgz2CSxPgrN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from scipy.stats import norm\n",
        "\n",
        "from models.VAE import VariationalAutoencoder\n",
        "from utils.loaders import load_mnist, load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgeMH86gQs0r"
      },
      "outputs": [],
      "source": [
        "SECTION = 'vae'\n",
        "RUN_ID = '0002'\n",
        "DATA_NAME = 'digits'\n",
        "RUN_FOLDER = 'run/{}/'.format(SECTION)\n",
        "RUN_FOLDER += '_'.join([RUN_ID, DATA_NAME])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGQIqYUSQvMq"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = load_mnist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfwYuhULQyKl"
      },
      "outputs": [],
      "source": [
        "vae = load_model(VariationalAutoencoder, RUN_FOLDER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wTeUIVqQ0JR"
      },
      "outputs": [],
      "source": [
        "n_to_show = 10\n",
        "np.random.seed(88)\n",
        "example_idx = np.random.choice(range(len(x_test)), n_to_show)\n",
        "example_images = x_test[example_idx]\n",
        "\n",
        "\n",
        "z_points = vae.encoder.predict(example_images)\n",
        "\n",
        "\n",
        "reconst_images = vae.decoder.predict(z_points)\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(15, 3))\n",
        "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "\n",
        "\n",
        "for i in range(n_to_show):\n",
        "    img = example_images[i].squeeze()\n",
        "    sub = fig.add_subplot(2, n_to_show, i+1)\n",
        "    sub.axis('off')\n",
        "    sub.text(0.5, -0.35, str(np.round(z_points[i],1)), fontsize=10, ha='center', transform=sub.transAxes)\n",
        "            \n",
        "    sub.imshow(img, cmap='gray_r')\n",
        "\n",
        "\n",
        "for i in range(n_to_show):\n",
        "    img = reconst_images[i].squeeze()\n",
        "    sub = fig.add_subplot(2, n_to_show, i+n_to_show+1)\n",
        "    sub.axis('off')\n",
        "    sub.imshow(img, cmap='gray_r')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4J0E7oZQ2wD"
      },
      "outputs": [],
      "source": [
        "n_to_show = 5000\n",
        "figsize = 12\n",
        "\n",
        "\n",
        "example_idx = np.random.choice(range(len(x_test)), n_to_show)\n",
        "example_images = x_test[example_idx]\n",
        "example_labels = y_test[example_idx]\n",
        "\n",
        "\n",
        "z_points = vae.encoder.predict(example_images)\n",
        "\n",
        "\n",
        "min_x = min(z_points[:, 0])\n",
        "max_x = max(z_points[:, 0])\n",
        "min_y = min(z_points[:, 1])\n",
        "max_y = max(z_points[:, 1])\n",
        "\n",
        "\n",
        "plt.figure(figsize=(figsize, figsize))\n",
        "plt.scatter(z_points[:, 0] , z_points[:, 1], c='black', alpha=0.5, s=2)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qe-kBn8_Q6jG"
      },
      "outputs": [],
      "source": [
        "figsize = 10\n",
        "plt.figure(figsize=(figsize, figsize))\n",
        "plt.scatter(z_points[:, 0] , z_points[:, 1], c='black', alpha=0.5, s=2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "grid_size = 15\n",
        "grid_depth = 2\n",
        "figsize = 15\n",
        "\n",
        "\n",
        "x = np.random.normal(size = grid_size * grid_depth)\n",
        "y = np.random.normal(size = grid_size * grid_depth)\n",
        "\n",
        "\n",
        "z_grid = np.array(list(zip(x, y)))\n",
        "reconst = vae.decoder.predict(z_grid)\n",
        "\n",
        "\n",
        "plt.scatter(z_grid[:, 0] , z_grid[:, 1], c = 'red', alpha=1, s=20)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(figsize, grid_depth))\n",
        "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "\n",
        "\n",
        "for i in range(grid_size*grid_depth):\n",
        "    ax = fig.add_subplot(grid_depth, grid_size, i+1)\n",
        "    ax.axis('off')\n",
        "    ax.text(0.5, -0.35, str(np.round(z_grid[i],1)), fontsize=8, ha='center', transform=ax.transAxes)\n",
        "    \n",
        "    ax.imshow(reconst[i, :,:,0], cmap = 'Greys')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LL4uzXHIQ-ih"
      },
      "outputs": [],
      "source": [
        "n_to_show = 5000\n",
        "grid_size = 15\n",
        "fig_height = 7\n",
        "fig_width = 15\n",
        "\n",
        "\n",
        "example_idx = np.random.choice(range(len(x_test)), n_to_show)\n",
        "example_images = x_test[example_idx]\n",
        "example_labels = y_test[example_idx]\n",
        "\n",
        "\n",
        "z_points = vae.encoder.predict(example_images)\n",
        "p_points = norm.cdf(z_points)\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(fig_width, fig_height))\n",
        "\n",
        "\n",
        "ax = fig.add_subplot(1, 2, 1)\n",
        "plot_1 = ax.scatter(z_points[:, 0] , z_points[:, 1] , cmap='rainbow' , c=example_labels\n",
        "            , alpha=0.5, s=2)\n",
        "plt.colorbar(plot_1)\n",
        "\n",
        "\n",
        "ax = fig.add_subplot(1, 2, 2)\n",
        "plot_2 = ax.scatter(p_points[:, 0] , p_points[:, 1] , cmap='rainbow' , c=example_labels\n",
        "            , alpha=0.5, s=5)\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPGVFYPjRA8l"
      },
      "outputs": [],
      "source": [
        "n_to_show = 5000\n",
        "grid_size = 20\n",
        "figsize = 10\n",
        "\n",
        "\n",
        "example_idx = np.random.choice(range(len(x_test)), n_to_show)\n",
        "example_images = x_test[example_idx]\n",
        "example_labels = y_test[example_idx]\n",
        "\n",
        "\n",
        "z_points = vae.encoder.predict(example_images)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(figsize, figsize))\n",
        "plt.scatter(z_points[:, 0] , z_points[:, 1] , cmap='rainbow' , c= example_labels\n",
        "            , alpha=0.5, s=2)\n",
        "plt.colorbar()\n",
        "\n",
        "\n",
        "x = norm.ppf(np.linspace(0.01, 0.99, grid_size))\n",
        "y = norm.ppf(np.linspace(0.01, 0.99, grid_size))\n",
        "xv, yv = np.meshgrid(x, y)\n",
        "xv = xv.flatten()\n",
        "yv = yv.flatten()\n",
        "z_grid = np.array(list(zip(xv, yv)))\n",
        "\n",
        "\n",
        "reconst = vae.decoder.predict(z_grid)\n",
        "\n",
        "\n",
        "plt.scatter(z_grid[:, 0] , z_grid[:, 1], c = 'black'#, cmap='rainbow' , c= example_labels\n",
        "            , alpha=1, s=2)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(figsize, figsize))\n",
        "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "for i in range(grid_size**2):\n",
        "    ax = fig.add_subplot(grid_size, grid_size, i+1)\n",
        "    ax.axis('off')\n",
        "    ax.imshow(reconst[i, :,:,0], cmap = 'Greys')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXphrrIxyYFn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "\n",
        "from models.VAE import VariationalAutoencoder\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmOkudQ4ylHx"
      },
      "outputs": [],
      "source": [
        "# run params\n",
        "section = 'vae'\n",
        "run_id = '0001'\n",
        "data_name = 'faces'\n",
        "RUN_FOLDER = 'run/{}/'.format(section)\n",
        "RUN_FOLDER += '_'.join([run_id, data_name])\n",
        "\n",
        "if not os.path.exists(RUN_FOLDER):\n",
        "    os.mkdir(RUN_FOLDER)\n",
        "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
        "    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\n",
        "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
        "\n",
        "mode =  'build' #'load' #\n",
        "\n",
        "\n",
        "DATA_FOLDER = './data/celeb/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCkmM8-u5SQy"
      },
      "outputs": [],
      "source": [
        "!mkdir data_faces && wget https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/celeba.zip "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xznC5pIq6m1Q"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(\"celeba.zip\",\"r\") as zip_ref:\n",
        "  zip_ref.extractall(\"data_faces/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kG5PKZhr60sr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "root = 'data_faces/img_align_celeba'\n",
        "img_list = os.listdir(root)\n",
        "print(len(img_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWxxVmEG9f4k"
      },
      "outputs": [],
      "source": [
        "!pip install Pillow>=4.1.1\n",
        "!pip install image\n",
        "!pip install torchtext==0.2.3\n",
        "!pip install seaborn --upgrade matplotlib\n",
        "!pip install seaborn --upgrade pandas\n",
        "!pip install seaborn --upgrade pillow\n",
        "!pip install seaborn --upgrade plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mi_w7Or6__F"
      },
      "outputs": [],
      "source": [
        "import PIL.Image as Image\n",
        "\"\"\" data \"\"\"\n",
        "crop_size = 108\n",
        "re_size = 64\n",
        "offset_height = (218 - crop_size) // 2\n",
        "offset_width = (178 - crop_size) // 2\n",
        "crop = lambda x: x[:, offset_height:offset_height + crop_size, offset_width:offset_width + crop_size]\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Lambda(crop),\n",
        "     transforms.ToPILImage(),\n",
        "     transforms.Scale(size=(re_size, re_size), interpolation=Image.BICUBIC),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize(mean=[0.5] * 3, std=[0.5] * 3)])\n",
        "\n",
        "batch_size = 64\n",
        "celeba_data = datasets.ImageFolder('./data_faces', transform=transform)\n",
        "data_loader = DataLoader(celeba_data,batch_size=batch_size,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06p7GYXx4-yT"
      },
      "outputs": [],
      "source": [
        "INPUT_DIM = (128,128,3)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "filenames = np.array(glob(os.path.join(DATA_FOLDER, '*/*.jpg')))\n",
        "\n",
        "NUM_IMAGES = len(filenames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4m8QbYJi5G18"
      },
      "outputs": [],
      "source": [
        "data_gen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "data_flow = data_gen.flow_from_directory(DATA_FOLDER\n",
        "                                         , target_size = INPUT_DIM[:2]\n",
        "                                         , batch_size = BATCH_SIZE\n",
        "                                         , shuffle = True\n",
        "                                         , class_mode = 'input'\n",
        "                                         , subset = \"training\"\n",
        "                                            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0hyJlNb8hpb"
      },
      "outputs": [],
      "source": [
        "vae = VariationalAutoencoder(\n",
        "                input_dim = INPUT_DIM\n",
        "                , encoder_conv_filters=[32,64,64, 64]\n",
        "                , encoder_conv_kernel_size=[3,3,3,3]\n",
        "                , encoder_conv_strides=[2,2,2,2]\n",
        "                , decoder_conv_t_filters=[64,64,32,3]\n",
        "                , decoder_conv_t_kernel_size=[3,3,3,3]\n",
        "                , decoder_conv_t_strides=[2,2,2,2]\n",
        "                , z_dim=200\n",
        "                , use_batch_norm=True\n",
        "                , use_dropout=True)\n",
        "\n",
        "if mode == 'build':\n",
        "    vae.save(RUN_FOLDER)\n",
        "else:\n",
        "    vae.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuaUvRtU8nkj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYrUqEvmK54e"
      },
      "outputs": [],
      "source": [
        "#Loading dataset\n",
        "mnist_dataset = datasets.MNIST(root='../data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "\n",
        "def show(img,renorm=False,nrow=8,interpolation='bicubic'):\n",
        "  if renorm:\n",
        "    img = img/2 + 0.5\n",
        "  img_grid = torchvision.utils.make_grid(img,nrow=nrow).numpy()\n",
        "  plt.figure()\n",
        "  plt.imshow(np.transpose(img_grid, (1,2,0)), interpolation=interpolation)\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "  \n",
        "image, label = mnist_dataset.__getitem__(2)\n",
        "show(image)\n",
        "print(label)\n",
        "print(image.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbEXvJBXLoD8"
      },
      "source": [
        "!pip install Pillow>=4.1.1\n",
        "!pip install image\n",
        "!pip install torchtext==0.2.3\n",
        "!pip install seaborn --upgrade matplotlib\n",
        "!pip install seaborn --upgrade pandas\n",
        "!pip install seaborn --upgrade pillow\n",
        "!pip install seaborn --upgrade plotly\n",
        "!pip install torchvision==0.1.9\n",
        "!pip install fastai==0.7.0\n",
        "!pip install PIL\n",
        "!pip install image\n",
        "import PIL.Image as Image\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import PIL.Image as Image\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "crop_size = 108\n",
        "re_size = 64\n",
        "offset_height = (218 - crop_size) // 2\n",
        "offset_width = (178 - crop_size) // 2\n",
        "crop = lambda x: x[:, offset_height:offset_height + crop_size, offset_width:offset_width + crop_size]\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Lambda(crop),\n",
        "     transforms.ToPILImage(),\n",
        "     transforms.Scale(size=(re_size, re_size), interpolation=Image.BICUBIC),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize(mean=[0.5] * 3, std=[0.5] * 3)])\n",
        "batch_size = 64\n",
        "celeba_data = datasets.ImageFolder('./data_faces', transform=transform)\n",
        "data_loader = DataLoader(celeba_data,batch_size=batch_size,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBSCMTOgMhpk"
      },
      "outputs": [],
      "source": [
        "def show(img,renorm=False,nrow=8,interpolation='bicubic'):\n",
        "  if renorm:\n",
        "    img = img/2 + 0.5\n",
        "  img_grid = torchvision.utils.make_grid(img,nrow=nrow).numpy()\n",
        "  plt.figure()\n",
        "  plt.imshow(np.transpose(img_grid, (1,2,0)), interpolation=interpolation)\n",
        "  plt.axis('off')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcdkbLS-OKXl"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(\"celeba.zip\",\"r\") as zip_ref:\n",
        "  zip_ref.extractall(\"data_faces/\")\n",
        "\n",
        "import os\n",
        "root = 'data_faces/img_align_celeba'\n",
        "img_list = os.listdir(root)\n",
        "print(len(img_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E04QepNbOdG_"
      },
      "outputs": [],
      "source": [
        "import PIL.Image as Image\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import PIL.Image as Image\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "crop_size = 108\n",
        "re_size = 64\n",
        "offset_height = (218 - crop_size) // 2\n",
        "offset_width = (178 - crop_size) // 2\n",
        "crop = lambda x: x[:, offset_height:offset_height + crop_size, offset_width:offset_width + crop_size]\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Lambda(crop),\n",
        "     transforms.ToPILImage(),\n",
        "     transforms.Scale(size=(re_size, re_size), interpolation=Image.BICUBIC),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize(mean=[0.5] * 3, std=[0.5] * 3)])\n",
        "\n",
        "batch_size = 64\n",
        "celeba_data = datasets.ImageFolder('./data_faces', transform=transform)\n",
        "data_loader = DataLoader(celeba_data,batch_size=batch_size,shuffle=True)\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show(img,renorm=False,nrow=8,interpolation='bicubic'):\n",
        "  if renorm:\n",
        "    img = img/2 + 0.5\n",
        "  img_grid = torchvision.utils.make_grid(img,nrow=nrow).numpy()\n",
        "  plt.figure()\n",
        "  plt.imshow(np.transpose(img_grid, (1,2,0)), interpolation=interpolation)\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "batch, _ = next(iter(data_loader))\n",
        "\n",
        "\n",
        "\n",
        "show(batch[0:16], renorm = True, nrow=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSa5WCbwQvCg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from scipy.stats import norm\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "from models.VAE import VariationalAutoencoder\n",
        "from utils.loaders import load_model, ImageLabelLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5csDhrnQzSb"
      },
      "outputs": [],
      "source": [
        "section = 'vae'\n",
        "run_id = '0001'\n",
        "data_name = 'faces'\n",
        "RUN_FOLDER = 'run/{}/'.format(section)\n",
        "RUN_FOLDER += '_'.join([run_id, data_name])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "DATA_FOLDER = './data/celeb/'\n",
        "IMAGE_FOLDER = './data/celeb/img_align_celeba/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oU_SyI7SQ211"
      },
      "outputs": [],
      "source": [
        "INPUT_DIM = (128,128,3)\n",
        "\n",
        "\n",
        "att = pd.read_csv(os.path.join(DATA_FOLDER, 'list_attr_celeba.csv'))\n",
        "\n",
        "\n",
        "imageLoader = ImageLabelLoader(IMAGE_FOLDER, INPUT_DIM[:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoxibubjRY-V"
      },
      "outputs": [],
      "source": [
        "att.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46oKScqlRl9n"
      },
      "outputs": [],
      "source": [
        "vae = load_model(VariationalAutoencoder, RUN_FOLDER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHcFajVxSkoV"
      },
      "outputs": [],
      "source": [
        "n_to_show = 10\n",
        "\n",
        "data_flow_generic = imageLoader.build(att, n_to_show)\n",
        "\n",
        "example_batch = next(data_flow_generic)\n",
        "example_images = example_batch[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-VN6xzbTXXN"
      },
      "outputs": [],
      "source": [
        "\n",
        "z_points = vae.encoder.predict(example_images)\n",
        "\n",
        "print(z_points)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJWlBtoxTpz9"
      },
      "outputs": [],
      "source": [
        "reconst_images = vae.decoder.predict(z_points)\n",
        "\n",
        "fig = plt.figure(figsize=(15, 3))\n",
        "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "\n",
        "for i in range(n_to_show):\n",
        "    img = example_images[i].squeeze()\n",
        "    sub = fig.add_subplot(2, n_to_show, i+1)\n",
        "    sub.axis('off')        \n",
        "    sub.imshow(img)\n",
        "\n",
        "for i in range(n_to_show):\n",
        "    img = reconst_images[i].squeeze()\n",
        "    sub = fig.add_subplot(2, n_to_show, i+n_to_show+1)\n",
        "    sub.axis('off')\n",
        "    sub.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGan2x65Uoy3"
      },
      "outputs": [],
      "source": [
        "z_test = vae.encoder.predict_generator(data_flow_generic, steps = 20, verbose = 1)\n",
        "\n",
        "\n",
        "x = np.linspace(-3, 3, 100)\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(20, 20))\n",
        "fig.subplots_adjust(hspace=0.6, wspace=0.4)\n",
        "\n",
        "\n",
        "for i in range(50):\n",
        "    ax = fig.add_subplot(5, 10, i+1)\n",
        "    ax.hist(z_test[:,i], density=True, bins = 20)\n",
        "    ax.axis('off')\n",
        "    ax.text(0.5, -0.35, str(i), fontsize=10, ha='center', transform=ax.transAxes)\n",
        "    ax.plot(x,norm.pdf(x))\n",
        "\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9shpzTwUxBT"
      },
      "outputs": [],
      "source": [
        "n_to_show = 30\n",
        "\n",
        "\n",
        "znew = np.random.normal(size = (n_to_show,vae.z_dim))\n",
        "\n",
        "\n",
        "reconst = vae.decoder.predict(np.array(znew))\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(18, 5))\n",
        "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "for i in range(n_to_show):\n",
        "    ax = fig.add_subplot(3, 10, i+1)\n",
        "    ax.imshow(reconst[i, :,:,:])\n",
        "    ax.axis('off')\n",
        "\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-jxe5-yUzBW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "gan_museum_face.ipynb의 사본",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('yoloenv')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "11f4621a6099d58d907dd1f6e1cd9ae5f54e214efa265e8bfd71f590918087d0"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
