{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"8.3 Stacked Autoencoder.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Cdsc8UYAVfBG"},"source":["# 8. 비지도 학습\n","## 8.3 오토 인코더"]},{"cell_type":"code","metadata":{"id":"tqUjDf4qVfBJ"},"source":["import torch\n","import torchvision\n","from torchvision import transforms\n","import torch.nn.functional as F\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MAHGePgTVfBJ"},"source":["# CPU/GPU\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(f'{device} is available.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yzv5l_nOVfBL"},"source":["dataset = torchvision.datasets.MNIST('./data/', download=True, train=True, transform=transforms.ToTensor())\n","trainloader = torch.utils.data.DataLoader(dataset,batch_size=50,shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VFR0PqheVfBM"},"source":["class Autoencoder(nn.Module):\n","    def __init__(self):\n","        super(Autoencoder, self).__init__()\n","        self.encoder = nn.Sequential(\n","                        nn.Linear(784, 128), \n","                        nn.ReLU(), \n","                        nn.Linear(128, 32), \n","                        nn.ReLU(), \n","                        nn.Linear(32, 10), \n","                        nn.ReLU())        \n","        self.decoder = nn.Sequential(\n","                        nn.Linear(10, 32),\n","                        nn.ReLU(),\n","                        nn.Linear(32, 128), \n","                        nn.ReLU(), \n","                        nn.Linear(128, 28*28) \n","                        #nn.Sigmoid()\n","        )\n","    \n","    def forward(self, x):       \n","        encoded = self.encoder(x)\n","        decoded = self.decoder(encoded)\n","        return decoded"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OuYyNqHnVfBM"},"source":["model = Autoencoder().to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"23p7FF1sVfBN"},"source":["def normalize_output(img):\n","    img = (img - img.min())/(img.max()-img.min())\n","    return img\n","\n","def check_plot():\n","    with torch.no_grad():\n","        for data in trainloader:\n","\n","            inputs = data[0].to(device)\n","            outputs = model(inputs.view(-1,28*28))\n","            outputs = outputs.view(-1,1,28,28)\n","            \n","            input_samples = inputs.permute(0,2,3,1).cpu().numpy() # 원래 이미지\n","            reconstructed_samples = outputs.permute(0,2,3,1).cpu().numpy() # 생성 이미지\n","            \n","            break # 배치 하나만 받고 for문 종료\n","\n","    #reconstructed_samples = normalize_output(reconstructed_samples) # 0~1사이로 변환\n","    #input_samples = normalize_output(input_samples) # 0~1사이로 변환\n","\n","    columns = 10 # 시각화 전체 너비 \n","    rows = 5 # 시각화 전체 높이 \n","\n","    fig=plt.figure(figsize=(columns, rows)) # figure 선언\n","\n","    for i in range(1, columns*rows+1):\n","        img = input_samples[i-1]\n","        fig.add_subplot(rows, columns, i)\n","        plt.imshow(img.squeeze())\n","        plt.axis('off')\n","    plt.show()\n","    plt.close()\n","\n","    fig=plt.figure(figsize=(columns, rows))\n","\n","    for i in range(1, columns*rows+1):\n","        img = reconstructed_samples[i-1]\n","        fig.add_subplot(rows, columns, i)\n","        plt.imshow(img.squeeze())\n","        plt.axis('off')\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ND0AXyGhVfBO"},"source":["criterion = nn.MSELoss() # MSE 사용\n","optimizer = optim.Adam(model.parameters(), lr=1e-4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SEtv9JevVfBO"},"source":["for epoch in range(51):\n","\n","    running_loss = 0.0\n","    for data in trainloader:\n","\n","        inputs = data[0].to(device)\n","        optimizer.zero_grad()\n","        outputs = model(inputs.view(-1,28*28))\n","        outputs = outputs.view(-1,1,28,28)\n","        loss = criterion(inputs, outputs) # 라벨 대신 입력 이미지와 출력 이미지를 비교\n","\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","        \n","    cost = running_loss / len(trainloader)        \n","    print('[%d] loss: %.3f' %(epoch + 1, cost))  \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kEWcxuqL2B3F"},"source":["check_plot()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FMM2RCMfEM1D"},"source":[""],"execution_count":null,"outputs":[]}]}