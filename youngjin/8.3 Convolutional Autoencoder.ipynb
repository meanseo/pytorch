{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"8.3 Convolutional Autoencoder.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Cdsc8UYAVfBG"},"source":["# 8. 비지도 학습\n","## 8.3 오토 인코더"]},{"cell_type":"code","metadata":{"id":"tqUjDf4qVfBJ"},"source":["import torch\n","import torchvision\n","from torchvision import transforms\n","import torch.nn.functional as F\n","\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MAHGePgTVfBJ"},"source":["# CPU/GPU\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(f'{device} is available.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yzv5l_nOVfBL"},"source":["dataset = torchvision.datasets.MNIST('./data/', download=True, train=True, transform=transforms.ToTensor())\n","trainloader = torch.utils.data.DataLoader(dataset,batch_size=50,shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VFR0PqheVfBM"},"source":["class Flatten(torch.nn.Module): # 4D -> 2D로 계산하기\n","    def forward(self, x):\n","        batch_size = x.shape[0]\n","        return x.view(batch_size, -1) # (배치 수, 채널 수, 이미지 너비, 이미지 높이) -> (배치 수, 채널 수*이미지 너비*이미지 높이)\n","\n","class Deflatten(nn.Module): # 2D -> 4D로 계산하기\n","\n","    def __init__(self, k):\n","        super(Deflatten, self).__init__()\n","        self.k = k\n","        \n","    def forward(self, x):\n","        s = x.size()\n","        \n","        # 벡터 사이즈 = 채널 수*이미지 너비*이미지 높이\n","        # 벡터 사이즈 = 채널 수*이미지 사이즈**2\n","        # 이미지 사이즈 = (벡터 사이즈//채널 수)**.5\n","        feature_size = int((s[1]//self.k)**.5) \n","        \n","        return x.view(s[0],self.k,feature_size,feature_size) # (배치 수, 채널 수*이미지 너비*이미지 높이) -> (배치 수, 채널 수, 이미지 너비, 이미지 높이) \n","    \n","\n","class Autoencoder(nn.Module):\n","    def __init__(self):\n","        super(Autoencoder, self).__init__()\n","        \n","        k = 16\n","        self.encoder = nn.Sequential(\n","                        nn.Conv2d(1, k, 3, stride=2), \n","                        nn.ReLU(), \n","                        nn.Conv2d(k, 2*k, 3, stride=2),\n","                        nn.ReLU(), \n","                        nn.Conv2d(2*k, 4*k, 3, stride=1),\n","                        nn.ReLU(),\n","                        Flatten(),\n","                        nn.Linear(1024, 10), \n","                        nn.ReLU()\n","        )\n","        \n","        # ConvTranspose2d\n","        # 입력 성분(Conv의 결과)을 출력 성분(Conv의 입력)으로 미분하여 그 값을 입력 벡터와 곱해 출력 벡터를 산출한다.\n","        # 출력 된 벡터는 행렬 형태로 변환한다.\n","        self.decoder = nn.Sequential(\n","                        nn.Linear(10, 1024),\n","                        nn.ReLU(),\n","                        Deflatten(4*k),\n","                        nn.ConvTranspose2d(4*k, 2*k, 3, stride=1), # (입력 채널 수, 출력 채널 수, 필터 크기, stride)\n","                        nn.ReLU(),\n","                        nn.ConvTranspose2d(2*k, k, 3, stride=2),\n","                        nn.ReLU(),\n","                        nn.ConvTranspose2d(k, 1, 3, stride=2,output_padding=1),\n","                        nn.Sigmoid()\n","        )\n","    \n","    def forward(self, x):\n","        \n","        encoded = self.encoder(x)\n","        decoded = self.decoder(encoded)\n","\n","        return decoded"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OuYyNqHnVfBM"},"source":["model = Autoencoder().to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"23p7FF1sVfBN"},"source":["def normalize_output(img):\n","    img = (img - img.min())/(img.max()-img.min())\n","    return img\n","\n","def check_plot():\n","    with torch.no_grad():\n","        for data in trainloader:\n","\n","            inputs = data[0].to(device)\n","            outputs = model(inputs)\n","            \n","            input_samples = inputs.permute(0,2,3,1).cpu().numpy() # 원래 이미지\n","            reconstructed_samples = outputs.permute(0,2,3,1).cpu().numpy() # 생성 이미지\n","            break # 배치 하나만 받고 for문 종료\n","\n","    #reconstructed_samples = normalize_output(reconstructed_samples) # 0~1사이로 변환\n","    #input_samples = normalize_output(input_samples) # 0~1사이로 변환\n","\n","    columns = 10 # 시각화 전체 너비 \n","    rows = 5 # 시각화 전체 높이 \n","\n","    fig=plt.figure(figsize=(columns, rows)) # figure 선언\n","\n","    # 원래 이미지 배치 크기 만큼 보여주기\n","    for i in range(1, columns*rows+1):\n","        img = input_samples[i-1]\n","        fig.add_subplot(rows, columns, i)\n","        plt.imshow(img.squeeze()) # 1채널인 경우 2로 변환\n","        #plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n","        plt.axis('off')\n","    plt.show()\n","\n","    # 생성 이미지 배치 크기 만큼 보여주기\n","    fig=plt.figure(figsize=(columns, rows))\n","\n","    for i in range(1, columns*rows+1):\n","        img = reconstructed_samples[i-1]\n","        fig.add_subplot(rows, columns, i)\n","        plt.imshow(img.squeeze())\n","        #plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n","        plt.axis('off')\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ND0AXyGhVfBO"},"source":["criterion = nn.MSELoss() # MSE 사용\n","optimizer = optim.Adam(model.parameters(), lr=1e-3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SEtv9JevVfBO"},"source":["for epoch in range(51):\n","\n","    running_loss = 0.0\n","    for data in trainloader:\n","\n","        inputs = data[0].to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        \n","        loss = criterion(inputs, outputs) # 라벨 대신 입력 이미지와 출력 이미지를 비교\n","\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","\n","\n","    cost = running_loss / len(trainloader)        \n","    \n","    if epoch % 10 == 0:\n","        print('[%d] loss: %.3f' %(epoch + 1, cost))  \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eKMSF4WzWPqx"},"source":["check_plot()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OC6AxQ70M9AC"},"source":[""],"execution_count":null,"outputs":[]}]}