{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"9.1 Regularization.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"EyfIVxAbURRU"},"source":["# 9. 성능 개선\n","## 9.1 과적합 - 여러 가지 정규화 기법"]},{"cell_type":"markdown","metadata":{"id":"fMTc4laPU1BB"},"source":["## Dropout & Batch Normalization\n"]},{"cell_type":"code","metadata":{"id":"jrBtSTGsU66B"},"source":["class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        \n","        self.feature_extraction = nn.Sequential(nn.Conv2d(3, 6, 5), \n","                                                nn.BatchNorm2d(6),\n","                                                nn.ReLU(),\n","                                                nn.MaxPool2d(2, 2), \n","                                                nn.Conv2d(6, 16, 5),\n","                                                nn.BatchNorm2d(16),\n","                                                nn.ReLU(),\n","                                                nn.MaxPool2d(2, 2))\n","        \n","        self.classifier = nn.Sequential(nn.Linear(512, 120),\n","                                        nn.ReLU(),\n","                                        nn.Dropout(0.5), # 비활성화 시킬 노드의 비율\n","                                        nn.Linear(120, 64),\n","                                        nn.ReLU(),\n","                                        nn.Linear(64, 10))\n","                                        \n","    def forward(self, x):\n","        x = self.feature_extraction(x)\n","        x = x.view(-1, 512) \n","        x = self.classifier(x)\n","\n","        return x\n","\n","net = CNN().to(device) # 모델 선언"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7lnvdVLDU9XD"},"source":["## L2 Regularization"]},{"cell_type":"code","metadata":{"id":"RT54D87fVAk5"},"source":["import torch.optim as optim\n","\n","optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ztEPe1J_VBD4"},"source":["## Data Augmentation"]},{"cell_type":"code","metadata":{"id":"fYiPkl_nVGDs"},"source":["import torchvision.transforms as tr\n","import PIL\n","\n","transf = tr.Compose(\n","                [tr.ToPILImage(), tr.RandomCrop(60), tr.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n","                 tr.RandomHorizontalFlip(),\n","                 tr.RandomRotation(10, resample=PIL.Image.BILINEAR),\n","                 tr.ToTensor()\n","                 ])"],"execution_count":null,"outputs":[]}]}